{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass: (214, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip3 install mlxtend\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import tree #C4.5\n",
    "from sklearn.ensemble import BaggingClassifier #Bagging\n",
    "from sklearn.ensemble import AdaBoostClassifier #Boosting\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forests\n",
    "from sklearn.ensemble import GradientBoostingClassifier #XGBoost\n",
    "from mlxtend.classifier import StackingClassifier #Stacking\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "pd.options.display.max_colwidth = 150\n",
    "\n",
    "data_glass = pd.read_csv(\"glass.data\")\n",
    "\n",
    "# to store the models and their results (to report)\n",
    "models, results, tempos = list(), list(), list()\n",
    "\n",
    "print('Glass:', np.shape(data_glass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1.51977</td>\n",
       "      <td>13.81</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.32</td>\n",
       "      <td>71.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>1.51786</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.19</td>\n",
       "      <td>72.95</td>\n",
       "      <td>0.62</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>1.51508</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>73.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.34</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>1.51753</td>\n",
       "      <td>12.57</td>\n",
       "      <td>3.47</td>\n",
       "      <td>1.38</td>\n",
       "      <td>73.39</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>204</td>\n",
       "      <td>1.51658</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a        b      c     d     e      f     g     h     i     j  target\n",
       "61    62  1.51977  13.81  3.58  1.32  71.72  0.12  8.67  0.69  0.00       1\n",
       "44    45  1.51786  12.73  3.43  1.19  72.95  0.62  8.76  0.00  0.30       1\n",
       "200  201  1.51508  15.15  0.00  2.25  73.50  0.00  8.34  0.63  0.00       7\n",
       "33    34  1.51753  12.57  3.47  1.38  73.39  0.60  8.55  0.00  0.06       1\n",
       "203  204  1.51658  14.80  0.00  1.99  73.11  0.00  8.28  1.71  0.00       7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_glass = shuffle(data_glass)\n",
    "data_glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_glass['target']\n",
    "data_glass = data_glass.drop(columns = ['target', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.493621</td>\n",
       "      <td>0.622270</td>\n",
       "      <td>-0.250765</td>\n",
       "      <td>-1.204728</td>\n",
       "      <td>-0.579492</td>\n",
       "      <td>-0.202111</td>\n",
       "      <td>1.038095</td>\n",
       "      <td>-0.586451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.166819</td>\n",
       "      <td>-0.832031</td>\n",
       "      <td>0.518033</td>\n",
       "      <td>-0.511756</td>\n",
       "      <td>0.387022</td>\n",
       "      <td>0.188951</td>\n",
       "      <td>-0.138723</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>2.499627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-1.084383</td>\n",
       "      <td>2.138411</td>\n",
       "      <td>-1.865511</td>\n",
       "      <td>1.616323</td>\n",
       "      <td>1.098781</td>\n",
       "      <td>-0.763919</td>\n",
       "      <td>-0.434534</td>\n",
       "      <td>0.917141</td>\n",
       "      <td>-0.586451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.275738</td>\n",
       "      <td>-1.028424</td>\n",
       "      <td>0.545830</td>\n",
       "      <td>-0.130308</td>\n",
       "      <td>0.956429</td>\n",
       "      <td>0.158213</td>\n",
       "      <td>-0.286629</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>0.030765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.589294</td>\n",
       "      <td>1.708802</td>\n",
       "      <td>-1.865511</td>\n",
       "      <td>1.094342</td>\n",
       "      <td>0.594079</td>\n",
       "      <td>-0.763919</td>\n",
       "      <td>-0.476793</td>\n",
       "      <td>3.094313</td>\n",
       "      <td>-0.586451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            b         c         d         e         f         g         h  \\\n",
       "61   0.463594  0.493621  0.622270 -0.250765 -1.204728 -0.579492 -0.202111   \n",
       "44  -0.166819 -0.832031  0.518033 -0.511756  0.387022  0.188951 -0.138723   \n",
       "200 -1.084383  2.138411 -1.865511  1.616323  1.098781 -0.763919 -0.434534   \n",
       "33  -0.275738 -1.028424  0.545830 -0.130308  0.956429  0.158213 -0.286629   \n",
       "203 -0.589294  1.708802 -1.865511  1.094342  0.594079 -0.763919 -0.476793   \n",
       "\n",
       "            i         j  \n",
       "61   1.038095 -0.586451  \n",
       "44  -0.352877  2.499627  \n",
       "200  0.917141 -0.586451  \n",
       "33  -0.352877  0.030765  \n",
       "203  3.094313 -0.586451  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the Glass dataset: standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_glass)\n",
    "data_glass[:] = scaler.transform(data_glass)\n",
    "data_glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "C45 = tree.DecisionTreeClassifier() \n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "#clf2 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "\n",
    "all_models=[C45, \n",
    "            BaggingClassifier(C45, max_samples=0.4),\n",
    "            AdaBoostClassifier(C45, n_estimators=100),\n",
    "            RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0),\n",
    "            GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, subsample=1.0),\n",
    "            StackingClassifier(classifiers=[clf1, clf2, C45], meta_classifier=lr)]\n",
    "\n",
    "models.extend(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=2019)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running models for Glass dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= Model:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') =======\n",
      "====\n",
      "Final results: \n",
      "Mean accuracy: 0.6774891774891776\n",
      "Mean traning model time:  0.0028728485107421876\n",
      "\n",
      "\n",
      "======= Model:  BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                        criterion='gini',\n",
      "                                                        max_depth=None,\n",
      "                                                        max_features=None,\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        presort=False,\n",
      "                                                        random_state=None,\n",
      "                                                        splitter='best'),\n",
      "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=0.4, n_estimators=10, n_jobs=None,\n",
      "                  oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False) =======\n",
      "====\n",
      "Final results: \n",
      "Mean accuracy: 0.6779220779220778\n",
      "Mean traning model time:  0.012642097473144532\n",
      "\n",
      "\n",
      "======= Model:  AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=None,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=100, random_state=None) =======\n",
      "====\n",
      "Final results: \n",
      "Mean accuracy: 0.6588744588744588\n",
      "Mean traning model time:  0.0030315160751342774\n",
      "\n",
      "\n",
      "======= Model:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False) =======\n",
      "====\n",
      "Final results: \n",
      "Mean accuracy: 0.6357142857142857\n",
      "Mean traning model time:  0.0825474739074707\n",
      "\n",
      "\n",
      "======= Model:  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) =======\n",
      "====\n",
      "Final results: \n",
      "Mean accuracy: 0.7393939393939395\n",
      "Mean traning model time:  0.4699427604675293\n",
      "\n",
      "\n",
      "======= Model:  StackingClassifier(average_probas=False,\n",
      "                   classifiers=[KNeighborsClassifier(algorithm='auto',\n",
      "                                                     leaf_size=30,\n",
      "                                                     metric='minkowski',\n",
      "                                                     metric_params=None,\n",
      "                                                     n_jobs=None, n_neighbors=1,\n",
      "                                                     p=2, weights='uniform'),\n",
      "                                GaussianNB(priors=None, var_smoothing=1e-09),\n",
      "                                DecisionTreeClassifier(class_weight=None,\n",
      "                                                       criterion='gini',\n",
      "                                                       max_depth=None,\n",
      "                                                       max_features=None,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_...\n",
      "                   meta_classifier=LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                      dual=False,\n",
      "                                                      fit_intercept=True,\n",
      "                                                      intercept_scaling=1,\n",
      "                                                      l1_ratio=None,\n",
      "                                                      max_iter=100,\n",
      "                                                      multi_class='warn',\n",
      "                                                      n_jobs=None, penalty='l2',\n",
      "                                                      random_state=None,\n",
      "                                                      solver='warn', tol=0.0001,\n",
      "                                                      verbose=0,\n",
      "                                                      warm_start=False),\n",
      "                   store_train_meta_features=False, use_clones=True,\n",
      "                   use_features_in_secondary=False, use_probas=False,\n",
      "                   verbose=0) =======\n",
      "Mean accuracy:  0.7066566283957588 KNN\n",
      "Mean accuracy:  0.446916682351465 Naive Bayes\n",
      "Mean accuracy:  0.6540777338603425 C4.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.6196605809649289 StackingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/afonso/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#For each model:\n",
    "aux = 0\n",
    "for model in all_models:\n",
    "    print('\\n\\n======= Model: ', model, '=======')\n",
    "    # for each fold:\n",
    "    accuracies = list()\n",
    "    times = list()\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(data_glass)):\n",
    "        #Builds the train and validation dataset, according to the current fold:\n",
    "        y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "        X_train, X_valid = data_glass.iloc[train_index,:].copy(), data_glass.iloc[test_index,:].copy()\n",
    "        # print(\"Fold\", i)\n",
    "        \n",
    "        #This condition is for the Stacking ensemble\n",
    "        if (aux == 5):\n",
    "                        \n",
    "            for clf, label in zip([clf1, clf2, C45, model], ['KNN', 'Naive Bayes','C4.5','StackingClassifier']):\n",
    "\n",
    "                scores = model_selection.cross_val_score(clf, data_glass, y, cv=10, scoring='accuracy')\n",
    "                print(\"Mean accuracy: \", scores.mean(), label)\n",
    "                \n",
    "            break\n",
    "                \n",
    "        else:\n",
    "            start = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            end = time.time()\n",
    "            times.append(end - start)\n",
    "            pred = model.predict(X_valid)\n",
    "            # print(confusion_matrix(y_valid, pred, labels=[1,2,3,5,6,7]))\n",
    "            acc = accuracy_score(pred, y_valid)\n",
    "            accuracies.append(acc)\n",
    "            \n",
    "    if(aux != 5):        \n",
    "        print('====\\nFinal results: \\nMean accuracy:', np.mean(accuracies))\n",
    "        print('Mean traning model time: ', np.mean(times))\n",
    "        results.append(np.mean(accuracies))\n",
    "        tempos.append(np.mean(times))\n",
    "    \n",
    "    aux += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
