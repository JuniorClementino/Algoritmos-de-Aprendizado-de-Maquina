{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn import svm\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nimport time\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import *\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\n\npd.options.display.max_colwidth = 150\ndata = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv('../input/test.csv')\ndata.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   Id  Elevation  Aspect     ...      Soil_Type39  Soil_Type40  Cover_Type\n0   1       2596      51     ...                0            0           5\n1   2       2590      56     ...                0            0           5\n2   3       2804     139     ...                0            0           2\n3   4       2785     155     ...                0            0           2\n4   5       2595      45     ...                0            0           5\n\n[5 rows x 56 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Elevation</th>\n      <th>Aspect</th>\n      <th>Slope</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Vertical_Distance_To_Hydrology</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Hillshade_3pm</th>\n      <th>Horizontal_Distance_To_Fire_Points</th>\n      <th>Wilderness_Area1</th>\n      <th>Wilderness_Area2</th>\n      <th>Wilderness_Area3</th>\n      <th>Wilderness_Area4</th>\n      <th>Soil_Type1</th>\n      <th>Soil_Type2</th>\n      <th>Soil_Type3</th>\n      <th>Soil_Type4</th>\n      <th>Soil_Type5</th>\n      <th>Soil_Type6</th>\n      <th>Soil_Type7</th>\n      <th>Soil_Type8</th>\n      <th>Soil_Type9</th>\n      <th>Soil_Type10</th>\n      <th>Soil_Type11</th>\n      <th>Soil_Type12</th>\n      <th>Soil_Type13</th>\n      <th>Soil_Type14</th>\n      <th>Soil_Type15</th>\n      <th>Soil_Type16</th>\n      <th>Soil_Type17</th>\n      <th>Soil_Type18</th>\n      <th>Soil_Type19</th>\n      <th>Soil_Type20</th>\n      <th>Soil_Type21</th>\n      <th>Soil_Type22</th>\n      <th>Soil_Type23</th>\n      <th>Soil_Type24</th>\n      <th>Soil_Type25</th>\n      <th>Soil_Type26</th>\n      <th>Soil_Type27</th>\n      <th>Soil_Type28</th>\n      <th>Soil_Type29</th>\n      <th>Soil_Type30</th>\n      <th>Soil_Type31</th>\n      <th>Soil_Type32</th>\n      <th>Soil_Type33</th>\n      <th>Soil_Type34</th>\n      <th>Soil_Type35</th>\n      <th>Soil_Type36</th>\n      <th>Soil_Type37</th>\n      <th>Soil_Type38</th>\n      <th>Soil_Type39</th>\n      <th>Soil_Type40</th>\n      <th>Cover_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2596</td>\n      <td>51</td>\n      <td>3</td>\n      <td>258</td>\n      <td>0</td>\n      <td>510</td>\n      <td>221</td>\n      <td>232</td>\n      <td>148</td>\n      <td>6279</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2590</td>\n      <td>56</td>\n      <td>2</td>\n      <td>212</td>\n      <td>-6</td>\n      <td>390</td>\n      <td>220</td>\n      <td>235</td>\n      <td>151</td>\n      <td>6225</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2804</td>\n      <td>139</td>\n      <td>9</td>\n      <td>268</td>\n      <td>65</td>\n      <td>3180</td>\n      <td>234</td>\n      <td>238</td>\n      <td>135</td>\n      <td>6121</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2785</td>\n      <td>155</td>\n      <td>18</td>\n      <td>242</td>\n      <td>118</td>\n      <td>3090</td>\n      <td>238</td>\n      <td>238</td>\n      <td>122</td>\n      <td>6211</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2595</td>\n      <td>45</td>\n      <td>2</td>\n      <td>153</td>\n      <td>-1</td>\n      <td>391</td>\n      <td>220</td>\n      <td>234</td>\n      <td>150</td>\n      <td>6172</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                Id     Elevation      ...        Soil_Type40    Cover_Type\ncount  15120.00000  15120.000000      ...       15120.000000  15120.000000\nmean    7560.50000   2749.322553      ...           0.030357      4.000000\nstd     4364.91237    417.678187      ...           0.171574      2.000066\nmin        1.00000   1863.000000      ...           0.000000      1.000000\n25%     3780.75000   2376.000000      ...           0.000000      2.000000\n50%     7560.50000   2752.000000      ...           0.000000      4.000000\n75%    11340.25000   3104.000000      ...           0.000000      6.000000\nmax    15120.00000   3849.000000      ...           1.000000      7.000000\n\n[8 rows x 56 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Elevation</th>\n      <th>Aspect</th>\n      <th>Slope</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Vertical_Distance_To_Hydrology</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Hillshade_3pm</th>\n      <th>Horizontal_Distance_To_Fire_Points</th>\n      <th>Wilderness_Area1</th>\n      <th>Wilderness_Area2</th>\n      <th>Wilderness_Area3</th>\n      <th>Wilderness_Area4</th>\n      <th>Soil_Type1</th>\n      <th>Soil_Type2</th>\n      <th>Soil_Type3</th>\n      <th>Soil_Type4</th>\n      <th>Soil_Type5</th>\n      <th>Soil_Type6</th>\n      <th>Soil_Type7</th>\n      <th>Soil_Type8</th>\n      <th>Soil_Type9</th>\n      <th>Soil_Type10</th>\n      <th>Soil_Type11</th>\n      <th>Soil_Type12</th>\n      <th>Soil_Type13</th>\n      <th>Soil_Type14</th>\n      <th>Soil_Type15</th>\n      <th>Soil_Type16</th>\n      <th>Soil_Type17</th>\n      <th>Soil_Type18</th>\n      <th>Soil_Type19</th>\n      <th>Soil_Type20</th>\n      <th>Soil_Type21</th>\n      <th>Soil_Type22</th>\n      <th>Soil_Type23</th>\n      <th>Soil_Type24</th>\n      <th>Soil_Type25</th>\n      <th>Soil_Type26</th>\n      <th>Soil_Type27</th>\n      <th>Soil_Type28</th>\n      <th>Soil_Type29</th>\n      <th>Soil_Type30</th>\n      <th>Soil_Type31</th>\n      <th>Soil_Type32</th>\n      <th>Soil_Type33</th>\n      <th>Soil_Type34</th>\n      <th>Soil_Type35</th>\n      <th>Soil_Type36</th>\n      <th>Soil_Type37</th>\n      <th>Soil_Type38</th>\n      <th>Soil_Type39</th>\n      <th>Soil_Type40</th>\n      <th>Cover_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>15120.00000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.0</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.0</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n      <td>15120.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7560.50000</td>\n      <td>2749.322553</td>\n      <td>156.676653</td>\n      <td>16.501587</td>\n      <td>227.195701</td>\n      <td>51.076521</td>\n      <td>1714.023214</td>\n      <td>212.704299</td>\n      <td>218.965608</td>\n      <td>135.091997</td>\n      <td>1511.147288</td>\n      <td>0.237897</td>\n      <td>0.033003</td>\n      <td>0.419907</td>\n      <td>0.309193</td>\n      <td>0.023479</td>\n      <td>0.041204</td>\n      <td>0.063624</td>\n      <td>0.055754</td>\n      <td>0.010913</td>\n      <td>0.042989</td>\n      <td>0.0</td>\n      <td>0.000066</td>\n      <td>0.000661</td>\n      <td>0.141667</td>\n      <td>0.026852</td>\n      <td>0.015013</td>\n      <td>0.031481</td>\n      <td>0.011177</td>\n      <td>0.0</td>\n      <td>0.007540</td>\n      <td>0.040476</td>\n      <td>0.003968</td>\n      <td>0.003042</td>\n      <td>0.009193</td>\n      <td>0.001058</td>\n      <td>0.022817</td>\n      <td>0.050066</td>\n      <td>0.016997</td>\n      <td>0.000066</td>\n      <td>0.003571</td>\n      <td>0.000992</td>\n      <td>0.000595</td>\n      <td>0.085384</td>\n      <td>0.047950</td>\n      <td>0.021958</td>\n      <td>0.045635</td>\n      <td>0.040741</td>\n      <td>0.001455</td>\n      <td>0.006746</td>\n      <td>0.000661</td>\n      <td>0.002249</td>\n      <td>0.048148</td>\n      <td>0.043452</td>\n      <td>0.030357</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4364.91237</td>\n      <td>417.678187</td>\n      <td>110.085801</td>\n      <td>8.453927</td>\n      <td>210.075296</td>\n      <td>61.239406</td>\n      <td>1325.066358</td>\n      <td>30.561287</td>\n      <td>22.801966</td>\n      <td>45.895189</td>\n      <td>1099.936493</td>\n      <td>0.425810</td>\n      <td>0.178649</td>\n      <td>0.493560</td>\n      <td>0.462176</td>\n      <td>0.151424</td>\n      <td>0.198768</td>\n      <td>0.244091</td>\n      <td>0.229454</td>\n      <td>0.103896</td>\n      <td>0.202840</td>\n      <td>0.0</td>\n      <td>0.008133</td>\n      <td>0.025710</td>\n      <td>0.348719</td>\n      <td>0.161656</td>\n      <td>0.121609</td>\n      <td>0.174621</td>\n      <td>0.105133</td>\n      <td>0.0</td>\n      <td>0.086506</td>\n      <td>0.197080</td>\n      <td>0.062871</td>\n      <td>0.055075</td>\n      <td>0.095442</td>\n      <td>0.032514</td>\n      <td>0.149326</td>\n      <td>0.218089</td>\n      <td>0.129265</td>\n      <td>0.008133</td>\n      <td>0.059657</td>\n      <td>0.031482</td>\n      <td>0.024391</td>\n      <td>0.279461</td>\n      <td>0.213667</td>\n      <td>0.146550</td>\n      <td>0.208699</td>\n      <td>0.197696</td>\n      <td>0.038118</td>\n      <td>0.081859</td>\n      <td>0.025710</td>\n      <td>0.047368</td>\n      <td>0.214086</td>\n      <td>0.203880</td>\n      <td>0.171574</td>\n      <td>2.000066</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>1863.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-146.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>99.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3780.75000</td>\n      <td>2376.000000</td>\n      <td>65.000000</td>\n      <td>10.000000</td>\n      <td>67.000000</td>\n      <td>5.000000</td>\n      <td>764.000000</td>\n      <td>196.000000</td>\n      <td>207.000000</td>\n      <td>106.000000</td>\n      <td>730.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>7560.50000</td>\n      <td>2752.000000</td>\n      <td>126.000000</td>\n      <td>15.000000</td>\n      <td>180.000000</td>\n      <td>32.000000</td>\n      <td>1316.000000</td>\n      <td>220.000000</td>\n      <td>223.000000</td>\n      <td>138.000000</td>\n      <td>1256.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>11340.25000</td>\n      <td>3104.000000</td>\n      <td>261.000000</td>\n      <td>22.000000</td>\n      <td>330.000000</td>\n      <td>79.000000</td>\n      <td>2270.000000</td>\n      <td>235.000000</td>\n      <td>235.000000</td>\n      <td>167.000000</td>\n      <td>1988.250000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15120.00000</td>\n      <td>3849.000000</td>\n      <td>360.000000</td>\n      <td>52.000000</td>\n      <td>1343.000000</td>\n      <td>554.000000</td>\n      <td>6890.000000</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>248.000000</td>\n      <td>6993.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_labels = data['Cover_Type'] - 1\ndata_train = data.drop(columns = ['Cover_Type', 'Id'])\ntest_ids = test['Id']\ndata_test = test.drop(columns=['Id'])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing the dataset: standardize features by removing the mean and scaling to unit variance\nscaler = StandardScaler()\nscaler.fit(data_train)\nscaler.fit(data_test)\ndata_train[:] = scaler.transform(data_train)\ndata_test[:] = scaler.transform(data_test)\n\nmodels, results, tempos = list(), list(), list()","execution_count":9,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n  \n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"Optimized models obtained after grid search:"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_models=[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n            colsample_bynode=0.9, colsample_bytree=0.9, gamma=0,\n            learning_rate=0.04, max_delta_step=0, max_depth=16,\n            max_features='log2', min_child_weight=1, missing=None,\n            n_estimators=400, n_jobs=1, nthread=None, num_class=7,\n            objective='multi:softprob', random_state=0, reg_alpha=0,\n            reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n            subsample=1),\n            \n            RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=13, max_features='sqrt', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False),\n           \n           GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=13,\n              max_features='sqrt', max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=8, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=400,\n              n_iter_no_change=None, presort='auto', random_state=None,\n              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False)\n           ]\n\nmodels.extend(all_models)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=2019)    ","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Running models for the dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For each model:\nfor model in all_models:\n    print('===========\\n Model: ', model)\n    # for each fold:\n    accuracies = list()\n    times = list()\n    \n    for i, (train_index, test_index) in enumerate(kf.split(data_train)):\n        #Builds the train and validation dataset, according to the current fold:\n        y_train, y_valid = data_labels.iloc[train_index].copy(), data_labels.iloc[test_index]\n        X_train, X_valid = data_train.iloc[train_index,:].copy(), data_train.iloc[test_index,:].copy()\n        start = time.time()\n        model.fit(X_train, y_train)\n        end = time.time()\n        times.append(end - start)\n        pred = model.predict(X_valid)\n        acc = accuracy_score(pred, y_valid)\n        accuracies.append(acc)\n        \n    print('Final results: \\nMean accuracy:', np.mean(accuracies))\n    print('Mean traning model time: ', np.mean(times))\n    print('============')\n    results.append(np.mean(accuracies))\n    tempos.append(np.mean(times))","execution_count":12,"outputs":[{"output_type":"stream","text":"===========\n Model:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n       colsample_bynode=0.9, colsample_bytree=0.9, gamma=0,\n       learning_rate=0.04, max_delta_step=0, max_depth=16,\n       max_features='log2', min_child_weight=1, missing=None,\n       n_estimators=400, n_jobs=1, nthread=None, num_class=7,\n       objective='multi:softprob', random_state=0, reg_alpha=0,\n       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n       subsample=1)\nFinal results: \nMean accuracy: 0.8736772486772487\nMean traning model time:  162.0060534477234\n============\n===========\n Model:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=13, max_features='sqrt', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\nFinal results: \nMean accuracy: 0.8322751322751323\nMean traning model time:  9.831897687911987\n============\n===========\n Model:  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=13,\n              max_features='sqrt', max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=8, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=400,\n              n_iter_no_change=None, presort='auto', random_state=None,\n              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False)\nFinal results: \nMean accuracy: 0.8673941798941799\nMean traning model time:  60.15134382247925\n============\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'Accuracy': results, 'Time': tempos, 'Model': models}\ndataframe = pd.DataFrame(data=data)\ndataframe = dataframe.sort_values(by=['Accuracy'], ascending=False)\ndataframe","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"   Accuracy                                                                          ...                                                                                                                                                                                                                            Model\n0  0.873677                                                                          ...                                                                            XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\\n       colsample_bynode=0.9, colsample_bytree=0.9, gamma=0,\\n       learni...\n2  0.867394                                                                          ...                                                                            ([DecisionTreeRegressor(criterion='friedman_mse', max_depth=13,\\n           max_features='sqrt', max_leaf_nodes=None,\\n           min_impurity_dec...\n1  0.832275                                                                          ...                                                                            (DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=13,\\n            max_features='sqrt', max_leaf_nodes=None,\\n            ...\n\n[3 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Time</th>\n      <th>Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.873677</td>\n      <td>162.006053</td>\n      <td>XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\\n       colsample_bynode=0.9, colsample_bytree=0.9, gamma=0,\\n       learni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.867394</td>\n      <td>60.151344</td>\n      <td>([DecisionTreeRegressor(criterion='friedman_mse', max_depth=13,\\n           max_features='sqrt', max_leaf_nodes=None,\\n           min_impurity_dec...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.832275</td>\n      <td>9.831898</td>\n      <td>(DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=13,\\n            max_features='sqrt', max_leaf_nodes=None,\\n            ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.to_csv('models_results.csv',index=False)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_index = 0\nfor model in all_models:\n    preds = model.predict(data_test) + 1\n    dataframe = pd.DataFrame(data={'Id': test_ids, 'Cover_Type': preds})\n    dataframe.to_csv('submission_model_'+str(model_index)+'.csv', index=False)\n    model_index += 1\n    print(dataframe.head())\n    ","execution_count":15,"outputs":[{"output_type":"stream","text":"      Id  Cover_Type\n0  15121           5\n1  15122           2\n2  15123           1\n3  15124           1\n4  15125           1\n      Id  Cover_Type\n0  15121           2\n1  15122           2\n2  15123           2\n3  15124           2\n4  15125           2\n      Id  Cover_Type\n0  15121           5\n1  15122           1\n2  15123           2\n3  15124           2\n4  15125           5\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}